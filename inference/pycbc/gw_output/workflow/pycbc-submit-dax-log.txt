Generating concrete workflow
2023.10.16 15:49:16.875 UTC: [WARNING]  --dax option is deprecated. The abstract workflow is passed via the last positional argument on the commandline. 
2023.10.16 15:49:16.886 UTC: [INFO]  Planner launched in the following directory /home/poseidon/workflows/pycbc/inference/pycbc/gw_output 
2023.10.16 15:49:16.886 UTC: [INFO]  Planner invoked with following arguments --conf ./pegasus-properties.conf --dir ./pycbc-tmp.6G7PELOUTq --submit --output-sites local --sites local,condorpool_shared --staging-site local=local,condorpool_shared=condorpool_shared --cluster label,horizontal --cleanup inplace --relative-dir work -q --dax gw.dax  
2023.10.16 15:49:16.888 UTC: [CONFIG]  Pegasus Properties set by the user 
2023.10.16 15:49:16.888 UTC: [CONFIG]  pegasus.catalog.replica.cache.asrc=true 
2023.10.16 15:49:16.888 UTC: [CONFIG]  pegasus.catalog.replica.dax.asrc=true 
2023.10.16 15:49:16.888 UTC: [CONFIG]  pegasus.catalog.workflow.amqp.url=amqp://friend:donatedata@msgs.pegasus.isi.edu:5672/prod/workflows 
2023.10.16 15:49:16.888 UTC: [CONFIG]  pegasus.dir.staging.mapper=Flat 
2023.10.16 15:49:16.889 UTC: [CONFIG]  pegasus.dir.storage.mapper=Replica 
2023.10.16 15:49:16.889 UTC: [CONFIG]  pegasus.dir.storage.mapper.replica=File 
2023.10.16 15:49:16.889 UTC: [CONFIG]  pegasus.dir.storage.mapper.replica.file=output.map 
2023.10.16 15:49:16.889 UTC: [CONFIG]  pegasus.dir.submit.mapper=Named 
2023.10.16 15:49:16.889 UTC: [CONFIG]  pegasus.file.cleanup.scope=deferred 
2023.10.16 15:49:16.889 UTC: [CONFIG]  pegasus.home.bindir=/usr/bin 
2023.10.16 15:49:16.889 UTC: [CONFIG]  pegasus.home.schemadir=/usr/share/pegasus/schema 
2023.10.16 15:49:16.890 UTC: [CONFIG]  pegasus.home.sharedstatedir=/usr/share/pegasus 
2023.10.16 15:49:16.890 UTC: [CONFIG]  pegasus.home.sysconfdir=/etc/pegasus 
2023.10.16 15:49:16.890 UTC: [CONFIG]  pegasus.integrity.checking=nosymlink 
2023.10.16 15:49:16.890 UTC: [CONFIG]  pegasus.metrics.app=ligo-pycbc 
2023.10.16 15:49:16.890 UTC: [CONFIG]  pegasus.mode=development 
2023.10.16 15:49:16.890 UTC: [CONFIG]  pegasus.monitord.encoding=json 
2023.10.16 15:49:16.890 UTC: [CONFIG]  pegasus.register=False 
2023.10.16 15:49:16.891 UTC: [CONFIG]  pegasus.selector.replica=Regex 
2023.10.16 15:49:16.891 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.1=osdf:///* 
2023.10.16 15:49:16.891 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.2=file://(?!.*(cvmfs)).* 
2023.10.16 15:49:16.891 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.3=file:///cvmfs/.* 
2023.10.16 15:49:16.891 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.4=root://.* 
2023.10.16 15:49:16.891 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.5=.* 
2023.10.16 15:49:16.891 UTC: [CONFIG]  pegasus.transfer.bypass.input.staging=true 
2023.10.16 15:49:16.891 UTC: [CONFIG]  pegasus.transfer.links=true 
2023.10.16 15:49:16.892 UTC: [CONFIG]  pegasus.transfer.worker.package=true 
2023.10.16 15:49:17.486 UTC: [INFO] event.pegasus.add.data-dependencies dax.id gw.dax-0  - STARTED 
2023.10.16 15:49:17.486 UTC: [INFO] event.pegasus.add.data-dependencies dax.id gw.dax-0  (0.0 seconds) - FINISHED 
2023.10.16 15:49:17.510 UTC: [CONFIG]  Loading site catalog file /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/sites.yml 
2023.10.16 15:49:17.582 UTC: [CONFIG]  Set environment profile for local site PATH=/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/poseidon/go/bin 
2023.10.16 15:49:17.583 UTC: [CONFIG]  Constructed default site catalog entry for condorpool site <site  handle="condorpool" arch="x86_64" os="linux" osrelease="" osversion="" glibc="">
	<profile namespace="pegasus" key="style" >condor</profile>
</site>
 
2023.10.16 15:49:17.842 UTC: [CONFIG]  Transformation Catalog Type used YAML TC 
2023.10.16 15:49:17.844 UTC: [CONFIG]  Transformation Catalog Type used Multiline Textual TC 
2023.10.16 15:49:17.844 UTC: [CONFIG]  Transformation Catalog File used /tmp/tc.2396322340797404215.txt 
2023.10.16 15:49:17.845 UTC: [CONFIG]  Data Configuration used for the workflow condorio 
2023.10.16 15:49:17.847 UTC: [CONFIG]  Metrics file will be written out to /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.6G7PELOUTq/work/gw.dax-0.metrics 
2023.10.16 15:49:17.847 UTC: [CONFIG]  The base submit directory for the workflow        /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.6G7PELOUTq 
2023.10.16 15:49:17.847 UTC: [CONFIG]  The relative submit directory for the workflow    work 
2023.10.16 15:49:17.847 UTC: [CONFIG]  The relative execution directory for the workflow work 
2023.10.16 15:49:17.848 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  - STARTED 
2023.10.16 15:49:17.851 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  (0.003 seconds) - FINISHED 
2023.10.16 15:49:17.852 UTC: [INFO] event.pegasus.refinement dax.id gw.dax-0  - STARTED 
2023.10.16 15:49:17.856 UTC: [CONFIG]  Proxy used for Replica Catalog is /tmp/x509up_u1001 
2023.10.16 15:49:17.859 UTC: [INFO] event.pegasus.check.cyclic-dependencies dax.id gw.dax-0  - STARTED 
2023.10.16 15:49:17.860 UTC: [INFO] event.pegasus.check.cyclic-dependencies dax.id gw.dax-0  (0.0 seconds) - FINISHED 
2023.10.16 15:49:17.860 UTC: [CONFIG]  Data Reuse Scope for the workflow: full 
2023.10.16 15:49:17.861 UTC: [INFO] event.pegasus.reduce dax.id gw.dax-0  - STARTED 
2023.10.16 15:49:17.861 UTC: [INFO]  Nodes/Jobs Deleted from the Workflow during reduction  
2023.10.16 15:49:17.862 UTC: [INFO]  Nodes/Jobs Deleted from the Workflow during reduction  - DONE 
2023.10.16 15:49:17.862 UTC: [INFO] event.pegasus.reduce dax.id gw.dax-0  (0.001 seconds) - FINISHED 
2023.10.16 15:49:17.862 UTC: [INFO] event.pegasus.siteselection dax.id gw.dax-0  - STARTED 
2023.10.16 15:49:17.867 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  - STARTED 
2023.10.16 15:49:17.867 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  (0.0 seconds) - FINISHED 
2023.10.16 15:49:17.868 UTC: [INFO] event.pegasus.siteselection dax.id gw.dax-0  (0.006 seconds) - FINISHED 
2023.10.16 15:49:17.879 UTC: [CONFIG]  No Replica Registration Jobs will be created . 
2023.10.16 15:49:17.882 UTC: [CONFIG]  Transfer Implementation loaded for Stage-In   [Python based Transfer Script] 
2023.10.16 15:49:17.882 UTC: [CONFIG]  Transfer Implementation loaded for symbolic linking Stage-In  [Python based Transfer Script] 
2023.10.16 15:49:17.882 UTC: [CONFIG]  Transfer Implementation loaded for Inter Site [Python based Transfer Script] 
2023.10.16 15:49:17.882 UTC: [CONFIG]  Transfer Implementation loaded for Stage-Out  [Python based Transfer Script] 
2023.10.16 15:49:17.885 UTC: [INFO] event.pegasus.cluster dax.id gw.dax-0  - STARTED 
2023.10.16 15:49:17.888 UTC: [CONFIG]  Partitioner loaded is Label Based Partitioning 
2023.10.16 15:49:17.893 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:49:17.895 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:49:17.895 UTC: [CONFIG]  Clusterer loaded is Topological based Vertical Clustering 
2023.10.16 15:49:17.895 UTC: [INFO]  Starting Graph Traversal 
2023.10.16 15:49:17.896 UTC: [INFO]  Starting Graph Traversal - DONE 
2023.10.16 15:49:17.896 UTC: [INFO]  Determining relations between partitions 
2023.10.16 15:49:17.897 UTC: [INFO]  Determining relations between partitions - DONE 
2023.10.16 15:49:17.897 UTC: [CONFIG]  Partitioner loaded is Level Based Partitioning 
2023.10.16 15:49:17.898 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:49:17.899 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:49:17.899 UTC: [CONFIG]  Clusterer loaded is Horizontal Clustering 
2023.10.16 15:49:17.900 UTC: [INFO] event.pegasus.cluster dax.id gw.dax-0  (0.015 seconds) - FINISHED 
2023.10.16 15:49:17.901 UTC: [INFO]  Grafting transfer nodes in the workflow 
2023.10.16 15:49:17.902 UTC: [INFO] event.pegasus.generate.transfer-nodes dax.id gw.dax-0  - STARTED 
2023.10.16 15:49:17.906 UTC: [CONFIG]  No Replica Registration Jobs will be created . 
2023.10.16 15:49:17.907 UTC: [CONFIG]  Transfer Implementation loaded for Stage-In   [Python based Transfer Script] 
2023.10.16 15:49:17.907 UTC: [CONFIG]  Transfer Implementation loaded for symbolic linking Stage-In  [Python based Transfer Script] 
2023.10.16 15:49:17.908 UTC: [CONFIG]  Transfer Implementation loaded for Inter Site [Python based Transfer Script] 
2023.10.16 15:49:17.908 UTC: [CONFIG]  Transfer Implementation loaded for Stage-Out  [Python based Transfer Script] 
2023.10.16 15:49:17.909 UTC: [CONFIG]  [RegexReplicaSelector] User Provided Ranked regexes are [( rank => 1 priority => 400 expr => osdf:///*), ( rank => 2 priority => 300 expr => file://(?!.*(cvmfs)).*), ( rank => 3 priority => 200 expr => file:///cvmfs/.*), ( rank => 4 priority => 100 expr => root://.*), ( rank => 5 priority => 0 expr => .*)] 
2023.10.16 15:49:17.912 UTC: [CONFIG]  Output Mapper loaded is              [Replica Catalog Mapper] 
2023.10.16 15:49:17.913 UTC: [CONFIG]  Transfer Refiner loaded is           [Balanced Cluster Transfer Refiner( round robin distribution at file level)] 
2023.10.16 15:49:17.913 UTC: [CONFIG]  ReplicaSelector loaded is            [Regex] 
2023.10.16 15:49:17.913 UTC: [CONFIG]  Submit Directory Mapper loaded is    [Relative Submit Directory Mapper] 
2023.10.16 15:49:17.913 UTC: [CONFIG]  Staging Mapper loaded is             [Flat Directory Staging Mapper] 
2023.10.16 15:49:17.916 UTC: [INFO] event.pegasus.generate.transfer-nodes dax.id gw.dax-0  (0.014 seconds) - FINISHED 
2023.10.16 15:49:17.917 UTC: [INFO] event.pegasus.generate.workdir-nodes dax.id gw.dax-0  - STARTED 
2023.10.16 15:49:17.919 UTC: [INFO] event.pegasus.generate.workdir-nodes dax.id gw.dax-0  (0.002 seconds) - FINISHED 
2023.10.16 15:49:17.919 UTC: [INFO] event.pegasus.generate.cleanup-nodes dax.id gw.dax-0  - STARTED 
2023.10.16 15:49:17.921 UTC: [CONFIG]  Setting property dagman.cleanup.maxjobs to  4 to set max jobs for cleanup jobs category 
2023.10.16 15:49:17.922 UTC: [INFO]  For site: local number of files cleaned up - 0 
2023.10.16 15:49:17.922 UTC: [INFO] event.pegasus.generate.cleanup-nodes dax.id gw.dax-0  (0.003 seconds) - FINISHED 
2023.10.16 15:49:17.922 UTC: [INFO] Adding Leaf Cleanup Jobs dax.id gw.dax-0  - STARTED 
2023.10.16 15:49:17.924 UTC: [INFO] Adding Leaf Cleanup Jobs dax.id gw.dax-0  (0.002 seconds) - FINISHED 
2023.10.16 15:49:17.925 UTC: [INFO] event.pegasus.refinement dax.id gw.dax-0  (0.073 seconds) - FINISHED 
2023.10.16 15:49:17.941 UTC: [INFO]  Generating codes for the executable workflow 
2023.10.16 15:49:17.941 UTC: [INFO] event.pegasus.code.generation dax.id gw.dax-0  - STARTED 
2023.10.16 15:49:17.942 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:49:17.957 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:49:18.191 UTC: [CONFIG]  Enforce strict checks for worker package in PegasusLite: true 
2023.10.16 15:49:18.191 UTC: [CONFIG]  Allow download of worker package in PegasusLite from Pegasus Website: true 
2023.10.16 15:49:18.193 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:49:18.204 UTC: [CONFIG]  Enforce strict checks for worker package in PegasusLite: false 
2023.10.16 15:49:18.204 UTC: [CONFIG]  Allow download of worker package in PegasusLite from Pegasus Website: false 
2023.10.16 15:49:18.205 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:49:18.605 UTC:    
2023.10.16 15:49:18.615 UTC:   ----------------------------------------------------------------------- 
2023.10.16 15:49:18.620 UTC:   File for submitting this DAG to HTCondor           : gw.dax-0.dag.condor.sub 
2023.10.16 15:49:18.625 UTC:   Log of DAGMan debugging messages                 : gw.dax-0.dag.dagman.out 
2023.10.16 15:49:18.631 UTC:   Log of HTCondor library output                     : gw.dax-0.dag.lib.out 
2023.10.16 15:49:18.636 UTC:   Log of HTCondor library error messages             : gw.dax-0.dag.lib.err 
2023.10.16 15:49:18.641 UTC:   Log of the life of condor_dagman itself          : gw.dax-0.dag.dagman.log 
2023.10.16 15:49:18.646 UTC:    
2023.10.16 15:49:18.651 UTC:   -no_submit given, not submitting DAG to HTCondor.  You can do this with: 
2023.10.16 15:49:18.661 UTC:   ----------------------------------------------------------------------- 
2023.10.16 15:49:18.668 UTC: [INFO] event.pegasus.code.generation dax.id gw.dax-0  (0.727 seconds) - FINISHED 
2023.10.16 15:49:19.697 UTC:   Database version: '5.0.6' (sqlite:////home/poseidon/.pegasus/workflow.db) 
2023.10.16 15:49:20.881 UTC:   Pegasus database was successfully created. 
2023.10.16 15:49:20.886 UTC:   Database version: '5.0.6' (sqlite:////home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.6G7PELOUTq/work/gw.dax-0.replicas.db) 
2023.10.16 15:49:20.923 UTC:   Output replica catalog set to jdbc:sqlite:/home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.6G7PELOUTq/work/gw.dax-0.replicas.db 
2023.10.16 15:49:21.140 UTC:   Submitting to condor gw.dax-0.dag.condor.sub 
2023.10.16 15:49:21.711 UTC:    
2023.10.16 15:49:21.712 UTC:   Submitting job(s). 
2023.10.16 15:49:21.716 UTC:   Your workflow has been started and is running in the base directory: 
2023.10.16 15:49:21.717 UTC:   1 job(s) submitted to cluster 74. 
2023.10.16 15:49:21.722 UTC:    
2023.10.16 15:49:21.727 UTC:   /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.6G7PELOUTq/work 
2023.10.16 15:49:21.732 UTC:    
2023.10.16 15:49:21.737 UTC:   *** To monitor the workflow you can run *** 
2023.10.16 15:49:21.743 UTC:    
2023.10.16 15:49:21.748 UTC:   pegasus-status -l /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.6G7PELOUTq/work 
2023.10.16 15:49:21.753 UTC:    
2023.10.16 15:49:21.759 UTC:   *** To remove your workflow run *** 
2023.10.16 15:49:21.764 UTC:    
2023.10.16 15:49:21.769 UTC:   pegasus-remove /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.6G7PELOUTq/work 
2023.10.16 15:49:22.021 UTC:   Time taken to execute is 5.004 seconds 
2023.10.16 15:49:22.021 UTC: [INFO] event.pegasus.planner planner.version 5.0.6  (5.156 seconds) - FINISHED 

Workflow submission completed successfully.

The Pegasus dashboard URL for this workflow is:
  https:///pegasus/u/poseidon/r//w?wf_uuid=

Note that it make take a while for the dashboard entry to appear while the workflow
is parsed by the dashboard. The delay can be on the order of one hour for very large
workflows.

Generating concrete workflow
2023.10.16 15:58:20.221 UTC: [WARNING]  --dax option is deprecated. The abstract workflow is passed via the last positional argument on the commandline. 
2023.10.16 15:58:20.232 UTC: [INFO]  Planner launched in the following directory /home/poseidon/workflows/pycbc/inference/pycbc/gw_output 
2023.10.16 15:58:20.232 UTC: [INFO]  Planner invoked with following arguments --conf ./pegasus-properties.conf --dir ./pycbc-tmp.DJrtMCxHnX --submit --output-sites local --sites local,condorpool_shared --staging-site local=local,condorpool_shared=condorpool_shared --cluster label,horizontal --cleanup inplace --relative-dir work -q --dax gw.dax  
2023.10.16 15:58:20.234 UTC: [CONFIG]  Pegasus Properties set by the user 
2023.10.16 15:58:20.234 UTC: [CONFIG]  pegasus.catalog.replica.cache.asrc=true 
2023.10.16 15:58:20.234 UTC: [CONFIG]  pegasus.catalog.replica.dax.asrc=true 
2023.10.16 15:58:20.234 UTC: [CONFIG]  pegasus.catalog.workflow.amqp.url=amqp://friend:donatedata@msgs.pegasus.isi.edu:5672/prod/workflows 
2023.10.16 15:58:20.235 UTC: [CONFIG]  pegasus.dir.staging.mapper=Flat 
2023.10.16 15:58:20.235 UTC: [CONFIG]  pegasus.dir.storage.mapper=Replica 
2023.10.16 15:58:20.235 UTC: [CONFIG]  pegasus.dir.storage.mapper.replica=File 
2023.10.16 15:58:20.235 UTC: [CONFIG]  pegasus.dir.storage.mapper.replica.file=output.map 
2023.10.16 15:58:20.235 UTC: [CONFIG]  pegasus.dir.submit.mapper=Named 
2023.10.16 15:58:20.235 UTC: [CONFIG]  pegasus.file.cleanup.scope=deferred 
2023.10.16 15:58:20.235 UTC: [CONFIG]  pegasus.home.bindir=/usr/bin 
2023.10.16 15:58:20.236 UTC: [CONFIG]  pegasus.home.schemadir=/usr/share/pegasus/schema 
2023.10.16 15:58:20.236 UTC: [CONFIG]  pegasus.home.sharedstatedir=/usr/share/pegasus 
2023.10.16 15:58:20.236 UTC: [CONFIG]  pegasus.home.sysconfdir=/etc/pegasus 
2023.10.16 15:58:20.236 UTC: [CONFIG]  pegasus.integrity.checking=nosymlink 
2023.10.16 15:58:20.236 UTC: [CONFIG]  pegasus.metrics.app=ligo-pycbc 
2023.10.16 15:58:20.236 UTC: [CONFIG]  pegasus.mode=development 
2023.10.16 15:58:20.236 UTC: [CONFIG]  pegasus.monitord.encoding=json 
2023.10.16 15:58:20.236 UTC: [CONFIG]  pegasus.register=False 
2023.10.16 15:58:20.237 UTC: [CONFIG]  pegasus.selector.replica=Regex 
2023.10.16 15:58:20.237 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.1=osdf:///* 
2023.10.16 15:58:20.237 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.2=file://(?!.*(cvmfs)).* 
2023.10.16 15:58:20.237 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.3=file:///cvmfs/.* 
2023.10.16 15:58:20.237 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.4=root://.* 
2023.10.16 15:58:20.237 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.5=.* 
2023.10.16 15:58:20.237 UTC: [CONFIG]  pegasus.transfer.bypass.input.staging=true 
2023.10.16 15:58:20.238 UTC: [CONFIG]  pegasus.transfer.links=true 
2023.10.16 15:58:20.238 UTC: [CONFIG]  pegasus.transfer.worker.package=true 
2023.10.16 15:58:20.823 UTC: [INFO] event.pegasus.add.data-dependencies dax.id gw.dax-0  - STARTED 
2023.10.16 15:58:20.824 UTC: [INFO] event.pegasus.add.data-dependencies dax.id gw.dax-0  (0.0 seconds) - FINISHED 
2023.10.16 15:58:20.847 UTC: [CONFIG]  Loading site catalog file /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/sites.yml 
2023.10.16 15:58:20.918 UTC: [CONFIG]  Set environment profile for local site PATH=/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/poseidon/go/bin 
2023.10.16 15:58:20.918 UTC: [CONFIG]  Constructed default site catalog entry for condorpool site <site  handle="condorpool" arch="x86_64" os="linux" osrelease="" osversion="" glibc="">
	<profile namespace="pegasus" key="style" >condor</profile>
</site>
 
2023.10.16 15:58:21.177 UTC: [CONFIG]  Transformation Catalog Type used YAML TC 
2023.10.16 15:58:21.178 UTC: [CONFIG]  Transformation Catalog Type used Multiline Textual TC 
2023.10.16 15:58:21.178 UTC: [CONFIG]  Transformation Catalog File used /tmp/tc.15920343881976076652.txt 
2023.10.16 15:58:21.180 UTC: [CONFIG]  Data Configuration used for the workflow condorio 
2023.10.16 15:58:21.181 UTC: [CONFIG]  Metrics file will be written out to /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.DJrtMCxHnX/work/gw.dax-0.metrics 
2023.10.16 15:58:21.182 UTC: [CONFIG]  The base submit directory for the workflow        /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.DJrtMCxHnX 
2023.10.16 15:58:21.182 UTC: [CONFIG]  The relative submit directory for the workflow    work 
2023.10.16 15:58:21.182 UTC: [CONFIG]  The relative execution directory for the workflow work 
2023.10.16 15:58:21.183 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  - STARTED 
2023.10.16 15:58:21.186 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  (0.003 seconds) - FINISHED 
2023.10.16 15:58:21.187 UTC: [INFO] event.pegasus.refinement dax.id gw.dax-0  - STARTED 
2023.10.16 15:58:21.191 UTC: [CONFIG]  Proxy used for Replica Catalog is /tmp/x509up_u1001 
2023.10.16 15:58:21.195 UTC: [INFO] event.pegasus.check.cyclic-dependencies dax.id gw.dax-0  - STARTED 
2023.10.16 15:58:21.195 UTC: [INFO] event.pegasus.check.cyclic-dependencies dax.id gw.dax-0  (0.0 seconds) - FINISHED 
2023.10.16 15:58:21.196 UTC: [CONFIG]  Data Reuse Scope for the workflow: full 
2023.10.16 15:58:21.196 UTC: [INFO] event.pegasus.reduce dax.id gw.dax-0  - STARTED 
2023.10.16 15:58:21.196 UTC: [INFO]  Nodes/Jobs Deleted from the Workflow during reduction  
2023.10.16 15:58:21.197 UTC: [INFO]  Nodes/Jobs Deleted from the Workflow during reduction  - DONE 
2023.10.16 15:58:21.197 UTC: [INFO] event.pegasus.reduce dax.id gw.dax-0  (0.001 seconds) - FINISHED 
2023.10.16 15:58:21.197 UTC: [INFO] event.pegasus.siteselection dax.id gw.dax-0  - STARTED 
2023.10.16 15:58:21.202 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  - STARTED 
2023.10.16 15:58:21.203 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  (0.001 seconds) - FINISHED 
2023.10.16 15:58:21.203 UTC: [INFO] event.pegasus.siteselection dax.id gw.dax-0  (0.006 seconds) - FINISHED 
2023.10.16 15:58:21.215 UTC: [CONFIG]  No Replica Registration Jobs will be created . 
2023.10.16 15:58:21.217 UTC: [CONFIG]  Transfer Implementation loaded for Stage-In   [Python based Transfer Script] 
2023.10.16 15:58:21.217 UTC: [CONFIG]  Transfer Implementation loaded for symbolic linking Stage-In  [Python based Transfer Script] 
2023.10.16 15:58:21.218 UTC: [CONFIG]  Transfer Implementation loaded for Inter Site [Python based Transfer Script] 
2023.10.16 15:58:21.218 UTC: [CONFIG]  Transfer Implementation loaded for Stage-Out  [Python based Transfer Script] 
2023.10.16 15:58:21.220 UTC: [INFO] event.pegasus.cluster dax.id gw.dax-0  - STARTED 
2023.10.16 15:58:21.223 UTC: [CONFIG]  Partitioner loaded is Label Based Partitioning 
2023.10.16 15:58:21.229 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:58:21.230 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:58:21.230 UTC: [CONFIG]  Clusterer loaded is Topological based Vertical Clustering 
2023.10.16 15:58:21.231 UTC: [INFO]  Starting Graph Traversal 
2023.10.16 15:58:21.231 UTC: [INFO]  Starting Graph Traversal - DONE 
2023.10.16 15:58:21.232 UTC: [INFO]  Determining relations between partitions 
2023.10.16 15:58:21.232 UTC: [INFO]  Determining relations between partitions - DONE 
2023.10.16 15:58:21.233 UTC: [CONFIG]  Partitioner loaded is Level Based Partitioning 
2023.10.16 15:58:21.234 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:58:21.234 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:58:21.234 UTC: [CONFIG]  Clusterer loaded is Horizontal Clustering 
2023.10.16 15:58:21.235 UTC: [INFO] event.pegasus.cluster dax.id gw.dax-0  (0.015 seconds) - FINISHED 
2023.10.16 15:58:21.237 UTC: [INFO]  Grafting transfer nodes in the workflow 
2023.10.16 15:58:21.237 UTC: [INFO] event.pegasus.generate.transfer-nodes dax.id gw.dax-0  - STARTED 
2023.10.16 15:58:21.241 UTC: [CONFIG]  No Replica Registration Jobs will be created . 
2023.10.16 15:58:21.243 UTC: [CONFIG]  Transfer Implementation loaded for Stage-In   [Python based Transfer Script] 
2023.10.16 15:58:21.243 UTC: [CONFIG]  Transfer Implementation loaded for symbolic linking Stage-In  [Python based Transfer Script] 
2023.10.16 15:58:21.243 UTC: [CONFIG]  Transfer Implementation loaded for Inter Site [Python based Transfer Script] 
2023.10.16 15:58:21.243 UTC: [CONFIG]  Transfer Implementation loaded for Stage-Out  [Python based Transfer Script] 
2023.10.16 15:58:21.245 UTC: [CONFIG]  [RegexReplicaSelector] User Provided Ranked regexes are [( rank => 1 priority => 400 expr => osdf:///*), ( rank => 2 priority => 300 expr => file://(?!.*(cvmfs)).*), ( rank => 3 priority => 200 expr => file:///cvmfs/.*), ( rank => 4 priority => 100 expr => root://.*), ( rank => 5 priority => 0 expr => .*)] 
2023.10.16 15:58:21.247 UTC: [CONFIG]  Output Mapper loaded is              [Replica Catalog Mapper] 
2023.10.16 15:58:21.248 UTC: [CONFIG]  Transfer Refiner loaded is           [Balanced Cluster Transfer Refiner( round robin distribution at file level)] 
2023.10.16 15:58:21.248 UTC: [CONFIG]  ReplicaSelector loaded is            [Regex] 
2023.10.16 15:58:21.248 UTC: [CONFIG]  Submit Directory Mapper loaded is    [Relative Submit Directory Mapper] 
2023.10.16 15:58:21.248 UTC: [CONFIG]  Staging Mapper loaded is             [Flat Directory Staging Mapper] 
2023.10.16 15:58:21.251 UTC: [INFO] event.pegasus.generate.transfer-nodes dax.id gw.dax-0  (0.014 seconds) - FINISHED 
2023.10.16 15:58:21.252 UTC: [INFO] event.pegasus.generate.workdir-nodes dax.id gw.dax-0  - STARTED 
2023.10.16 15:58:21.254 UTC: [INFO] event.pegasus.generate.workdir-nodes dax.id gw.dax-0  (0.002 seconds) - FINISHED 
2023.10.16 15:58:21.254 UTC: [INFO] event.pegasus.generate.cleanup-nodes dax.id gw.dax-0  - STARTED 
2023.10.16 15:58:21.256 UTC: [CONFIG]  Setting property dagman.cleanup.maxjobs to  4 to set max jobs for cleanup jobs category 
2023.10.16 15:58:21.257 UTC: [INFO]  For site: local number of files cleaned up - 0 
2023.10.16 15:58:21.257 UTC: [INFO] event.pegasus.generate.cleanup-nodes dax.id gw.dax-0  (0.003 seconds) - FINISHED 
2023.10.16 15:58:21.258 UTC: [INFO] Adding Leaf Cleanup Jobs dax.id gw.dax-0  - STARTED 
2023.10.16 15:58:21.259 UTC: [INFO] Adding Leaf Cleanup Jobs dax.id gw.dax-0  (0.001 seconds) - FINISHED 
2023.10.16 15:58:21.260 UTC: [INFO] event.pegasus.refinement dax.id gw.dax-0  (0.073 seconds) - FINISHED 
2023.10.16 15:58:21.278 UTC: [INFO]  Generating codes for the executable workflow 
2023.10.16 15:58:21.278 UTC: [INFO] event.pegasus.code.generation dax.id gw.dax-0  - STARTED 
2023.10.16 15:58:21.279 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:58:21.294 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:58:21.530 UTC: [CONFIG]  Enforce strict checks for worker package in PegasusLite: true 
2023.10.16 15:58:21.530 UTC: [CONFIG]  Allow download of worker package in PegasusLite from Pegasus Website: true 
2023.10.16 15:58:21.532 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:58:21.543 UTC: [CONFIG]  Enforce strict checks for worker package in PegasusLite: false 
2023.10.16 15:58:21.543 UTC: [CONFIG]  Allow download of worker package in PegasusLite from Pegasus Website: false 
2023.10.16 15:58:21.544 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 15:58:21.946 UTC:    
2023.10.16 15:58:21.951 UTC:   ----------------------------------------------------------------------- 
2023.10.16 15:58:21.957 UTC:   File for submitting this DAG to HTCondor           : gw.dax-0.dag.condor.sub 
2023.10.16 15:58:21.962 UTC:   Log of DAGMan debugging messages                 : gw.dax-0.dag.dagman.out 
2023.10.16 15:58:21.967 UTC:   Log of HTCondor library output                     : gw.dax-0.dag.lib.out 
2023.10.16 15:58:21.973 UTC:   Log of HTCondor library error messages             : gw.dax-0.dag.lib.err 
2023.10.16 15:58:21.978 UTC:   Log of the life of condor_dagman itself          : gw.dax-0.dag.dagman.log 
2023.10.16 15:58:21.983 UTC:    
2023.10.16 15:58:21.989 UTC:   -no_submit given, not submitting DAG to HTCondor.  You can do this with: 
2023.10.16 15:58:21.999 UTC:   ----------------------------------------------------------------------- 
2023.10.16 15:58:22.006 UTC: [INFO] event.pegasus.code.generation dax.id gw.dax-0  (0.728 seconds) - FINISHED 
2023.10.16 15:58:23.034 UTC:   Database version: '5.0.6' (sqlite:////home/poseidon/.pegasus/workflow.db) 
2023.10.16 15:58:24.211 UTC:   Pegasus database was successfully created. 
2023.10.16 15:58:24.217 UTC:   Database version: '5.0.6' (sqlite:////home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.DJrtMCxHnX/work/gw.dax-0.replicas.db) 
2023.10.16 15:58:24.271 UTC:   Output replica catalog set to jdbc:sqlite:/home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.DJrtMCxHnX/work/gw.dax-0.replicas.db 
2023.10.16 15:58:24.491 UTC:   Submitting to condor gw.dax-0.dag.condor.sub 
2023.10.16 15:58:25.065 UTC:   Submitting job(s). 
2023.10.16 15:58:25.065 UTC:    
2023.10.16 15:58:25.070 UTC:   1 job(s) submitted to cluster 95. 
2023.10.16 15:58:25.070 UTC:   Your workflow has been started and is running in the base directory: 
2023.10.16 15:58:25.075 UTC:    
2023.10.16 15:58:25.080 UTC:   /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.DJrtMCxHnX/work 
2023.10.16 15:58:25.085 UTC:    
2023.10.16 15:58:25.091 UTC:   *** To monitor the workflow you can run *** 
2023.10.16 15:58:25.096 UTC:    
2023.10.16 15:58:25.101 UTC:   pegasus-status -l /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.DJrtMCxHnX/work 
2023.10.16 15:58:25.106 UTC:    
2023.10.16 15:58:25.111 UTC:   *** To remove your workflow run *** 
2023.10.16 15:58:25.116 UTC:    
2023.10.16 15:58:25.121 UTC:   pegasus-remove /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.DJrtMCxHnX/work 
2023.10.16 15:58:25.353 UTC:   Time taken to execute is 5.001 seconds 
2023.10.16 15:58:25.354 UTC: [INFO] event.pegasus.planner planner.version 5.0.6  (5.139 seconds) - FINISHED 

Workflow submission completed successfully.

The Pegasus dashboard URL for this workflow is:
  https:///pegasus/u/poseidon/r//w?wf_uuid=

Note that it make take a while for the dashboard entry to appear while the workflow
is parsed by the dashboard. The delay can be on the order of one hour for very large
workflows.

Generating concrete workflow
2023.10.16 22:08:11.079 UTC: [WARNING]  --dax option is deprecated. The abstract workflow is passed via the last positional argument on the commandline. 
2023.10.16 22:08:11.091 UTC: [INFO]  Planner launched in the following directory /home/poseidon/workflows/pycbc/inference/pycbc/gw_output 
2023.10.16 22:08:11.091 UTC: [INFO]  Planner invoked with following arguments --conf ./pegasus-properties.conf --dir ./pycbc-tmp.yhoRUb9E5x --submit --output-sites local --sites local,condorpool_shared --staging-site local=local,condorpool_shared=condorpool_shared --cluster label,horizontal --cleanup inplace --relative-dir work -q --dax gw.dax  
2023.10.16 22:08:11.093 UTC: [CONFIG]  Pegasus Properties set by the user 
2023.10.16 22:08:11.093 UTC: [CONFIG]  pegasus.catalog.replica.cache.asrc=true 
2023.10.16 22:08:11.093 UTC: [CONFIG]  pegasus.catalog.replica.dax.asrc=true 
2023.10.16 22:08:11.093 UTC: [CONFIG]  pegasus.catalog.workflow.amqp.url=amqp://friend:donatedata@msgs.pegasus.isi.edu:5672/prod/workflows 
2023.10.16 22:08:11.093 UTC: [CONFIG]  pegasus.dir.staging.mapper=Flat 
2023.10.16 22:08:11.093 UTC: [CONFIG]  pegasus.dir.storage.mapper=Replica 
2023.10.16 22:08:11.093 UTC: [CONFIG]  pegasus.dir.storage.mapper.replica=File 
2023.10.16 22:08:11.093 UTC: [CONFIG]  pegasus.dir.storage.mapper.replica.file=output.map 
2023.10.16 22:08:11.093 UTC: [CONFIG]  pegasus.dir.submit.mapper=Named 
2023.10.16 22:08:11.093 UTC: [CONFIG]  pegasus.file.cleanup.scope=deferred 
2023.10.16 22:08:11.094 UTC: [CONFIG]  pegasus.home.bindir=/usr/bin 
2023.10.16 22:08:11.094 UTC: [CONFIG]  pegasus.home.schemadir=/usr/share/pegasus/schema 
2023.10.16 22:08:11.094 UTC: [CONFIG]  pegasus.home.sharedstatedir=/usr/share/pegasus 
2023.10.16 22:08:11.094 UTC: [CONFIG]  pegasus.home.sysconfdir=/etc/pegasus 
2023.10.16 22:08:11.094 UTC: [CONFIG]  pegasus.integrity.checking=nosymlink 
2023.10.16 22:08:11.094 UTC: [CONFIG]  pegasus.metrics.app=ligo-pycbc 
2023.10.16 22:08:11.094 UTC: [CONFIG]  pegasus.mode=development 
2023.10.16 22:08:11.094 UTC: [CONFIG]  pegasus.monitord.encoding=json 
2023.10.16 22:08:11.094 UTC: [CONFIG]  pegasus.register=False 
2023.10.16 22:08:11.094 UTC: [CONFIG]  pegasus.selector.replica=Regex 
2023.10.16 22:08:11.095 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.1=osdf:///* 
2023.10.16 22:08:11.095 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.2=file://(?!.*(cvmfs)).* 
2023.10.16 22:08:11.095 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.3=file:///cvmfs/.* 
2023.10.16 22:08:11.095 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.4=root://.* 
2023.10.16 22:08:11.095 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.5=.* 
2023.10.16 22:08:11.095 UTC: [CONFIG]  pegasus.transfer.bypass.input.staging=true 
2023.10.16 22:08:11.095 UTC: [CONFIG]  pegasus.transfer.links=true 
2023.10.16 22:08:11.095 UTC: [CONFIG]  pegasus.transfer.worker.package=true 
2023.10.16 22:08:11.698 UTC: [INFO] event.pegasus.add.data-dependencies dax.id gw.dax-0  - STARTED 
2023.10.16 22:08:11.699 UTC: [INFO] event.pegasus.add.data-dependencies dax.id gw.dax-0  (0.001 seconds) - FINISHED 
2023.10.16 22:08:11.722 UTC: [CONFIG]  Loading site catalog file /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/sites.yml 
2023.10.16 22:08:11.790 UTC: [CONFIG]  Set environment profile for local site PATH=/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/poseidon/go/bin 
2023.10.16 22:08:11.790 UTC: [CONFIG]  Constructed default site catalog entry for condorpool site <site  handle="condorpool" arch="x86_64" os="linux" osrelease="" osversion="" glibc="">
	<profile namespace="pegasus" key="style" >condor</profile>
</site>
 
2023.10.16 22:08:12.046 UTC: [CONFIG]  Transformation Catalog Type used YAML TC 
2023.10.16 22:08:12.048 UTC: [CONFIG]  Transformation Catalog Type used Multiline Textual TC 
2023.10.16 22:08:12.048 UTC: [CONFIG]  Transformation Catalog File used /tmp/tc.16264494132201034057.txt 
2023.10.16 22:08:12.050 UTC: [CONFIG]  Data Configuration used for the workflow condorio 
2023.10.16 22:08:12.051 UTC: [CONFIG]  Metrics file will be written out to /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.yhoRUb9E5x/work/gw.dax-0.metrics 
2023.10.16 22:08:12.051 UTC: [CONFIG]  The base submit directory for the workflow        /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.yhoRUb9E5x 
2023.10.16 22:08:12.051 UTC: [CONFIG]  The relative submit directory for the workflow    work 
2023.10.16 22:08:12.051 UTC: [CONFIG]  The relative execution directory for the workflow work 
2023.10.16 22:08:12.052 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  - STARTED 
2023.10.16 22:08:12.055 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  (0.003 seconds) - FINISHED 
2023.10.16 22:08:12.056 UTC: [INFO] event.pegasus.refinement dax.id gw.dax-0  - STARTED 
2023.10.16 22:08:12.059 UTC: [CONFIG]  Proxy used for Replica Catalog is /tmp/x509up_u1001 
2023.10.16 22:08:12.062 UTC: [INFO] event.pegasus.check.cyclic-dependencies dax.id gw.dax-0  - STARTED 
2023.10.16 22:08:12.063 UTC: [INFO] event.pegasus.check.cyclic-dependencies dax.id gw.dax-0  (0.001 seconds) - FINISHED 
2023.10.16 22:08:12.063 UTC: [CONFIG]  Data Reuse Scope for the workflow: full 
2023.10.16 22:08:12.064 UTC: [INFO] event.pegasus.reduce dax.id gw.dax-0  - STARTED 
2023.10.16 22:08:12.064 UTC: [INFO]  Nodes/Jobs Deleted from the Workflow during reduction  
2023.10.16 22:08:12.064 UTC: [INFO]  Nodes/Jobs Deleted from the Workflow during reduction  - DONE 
2023.10.16 22:08:12.064 UTC: [INFO] event.pegasus.reduce dax.id gw.dax-0  (0.0 seconds) - FINISHED 
2023.10.16 22:08:12.064 UTC: [INFO] event.pegasus.siteselection dax.id gw.dax-0  - STARTED 
2023.10.16 22:08:12.070 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  - STARTED 
2023.10.16 22:08:12.070 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  (0.0 seconds) - FINISHED 
2023.10.16 22:08:12.070 UTC: [INFO] event.pegasus.siteselection dax.id gw.dax-0  (0.006 seconds) - FINISHED 
2023.10.16 22:08:12.082 UTC: [CONFIG]  No Replica Registration Jobs will be created . 
2023.10.16 22:08:12.084 UTC: [CONFIG]  Transfer Implementation loaded for Stage-In   [Python based Transfer Script] 
2023.10.16 22:08:12.084 UTC: [CONFIG]  Transfer Implementation loaded for symbolic linking Stage-In  [Python based Transfer Script] 
2023.10.16 22:08:12.085 UTC: [CONFIG]  Transfer Implementation loaded for Inter Site [Python based Transfer Script] 
2023.10.16 22:08:12.085 UTC: [CONFIG]  Transfer Implementation loaded for Stage-Out  [Python based Transfer Script] 
2023.10.16 22:08:12.087 UTC: [INFO] event.pegasus.cluster dax.id gw.dax-0  - STARTED 
2023.10.16 22:08:12.089 UTC: [CONFIG]  Partitioner loaded is Label Based Partitioning 
2023.10.16 22:08:12.095 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:08:12.097 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:08:12.097 UTC: [CONFIG]  Clusterer loaded is Topological based Vertical Clustering 
2023.10.16 22:08:12.097 UTC: [INFO]  Starting Graph Traversal 
2023.10.16 22:08:12.097 UTC: [INFO]  Starting Graph Traversal - DONE 
2023.10.16 22:08:12.098 UTC: [INFO]  Determining relations between partitions 
2023.10.16 22:08:12.098 UTC: [INFO]  Determining relations between partitions - DONE 
2023.10.16 22:08:12.099 UTC: [CONFIG]  Partitioner loaded is Level Based Partitioning 
2023.10.16 22:08:12.100 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:08:12.100 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:08:12.100 UTC: [CONFIG]  Clusterer loaded is Horizontal Clustering 
2023.10.16 22:08:12.101 UTC: [INFO] event.pegasus.cluster dax.id gw.dax-0  (0.014 seconds) - FINISHED 
2023.10.16 22:08:12.103 UTC: [INFO]  Grafting transfer nodes in the workflow 
2023.10.16 22:08:12.103 UTC: [INFO] event.pegasus.generate.transfer-nodes dax.id gw.dax-0  - STARTED 
2023.10.16 22:08:12.107 UTC: [CONFIG]  No Replica Registration Jobs will be created . 
2023.10.16 22:08:12.108 UTC: [CONFIG]  Transfer Implementation loaded for Stage-In   [Python based Transfer Script] 
2023.10.16 22:08:12.108 UTC: [CONFIG]  Transfer Implementation loaded for symbolic linking Stage-In  [Python based Transfer Script] 
2023.10.16 22:08:12.108 UTC: [CONFIG]  Transfer Implementation loaded for Inter Site [Python based Transfer Script] 
2023.10.16 22:08:12.108 UTC: [CONFIG]  Transfer Implementation loaded for Stage-Out  [Python based Transfer Script] 
2023.10.16 22:08:12.110 UTC: [CONFIG]  [RegexReplicaSelector] User Provided Ranked regexes are [( rank => 1 priority => 400 expr => osdf:///*), ( rank => 2 priority => 300 expr => file://(?!.*(cvmfs)).*), ( rank => 3 priority => 200 expr => file:///cvmfs/.*), ( rank => 4 priority => 100 expr => root://.*), ( rank => 5 priority => 0 expr => .*)] 
2023.10.16 22:08:12.112 UTC: [CONFIG]  Output Mapper loaded is              [Replica Catalog Mapper] 
2023.10.16 22:08:12.113 UTC: [CONFIG]  Transfer Refiner loaded is           [Balanced Cluster Transfer Refiner( round robin distribution at file level)] 
2023.10.16 22:08:12.113 UTC: [CONFIG]  ReplicaSelector loaded is            [Regex] 
2023.10.16 22:08:12.113 UTC: [CONFIG]  Submit Directory Mapper loaded is    [Relative Submit Directory Mapper] 
2023.10.16 22:08:12.113 UTC: [CONFIG]  Staging Mapper loaded is             [Flat Directory Staging Mapper] 
2023.10.16 22:08:12.117 UTC: [INFO] event.pegasus.generate.transfer-nodes dax.id gw.dax-0  (0.014 seconds) - FINISHED 
2023.10.16 22:08:12.117 UTC: [INFO] event.pegasus.generate.workdir-nodes dax.id gw.dax-0  - STARTED 
2023.10.16 22:08:12.119 UTC: [INFO] event.pegasus.generate.workdir-nodes dax.id gw.dax-0  (0.002 seconds) - FINISHED 
2023.10.16 22:08:12.119 UTC: [INFO] event.pegasus.generate.cleanup-nodes dax.id gw.dax-0  - STARTED 
2023.10.16 22:08:12.121 UTC: [CONFIG]  Setting property dagman.cleanup.maxjobs to  4 to set max jobs for cleanup jobs category 
2023.10.16 22:08:12.122 UTC: [INFO]  For site: local number of files cleaned up - 0 
2023.10.16 22:08:12.122 UTC: [INFO] event.pegasus.generate.cleanup-nodes dax.id gw.dax-0  (0.003 seconds) - FINISHED 
2023.10.16 22:08:12.123 UTC: [INFO] Adding Leaf Cleanup Jobs dax.id gw.dax-0  - STARTED 
2023.10.16 22:08:12.124 UTC: [INFO] Adding Leaf Cleanup Jobs dax.id gw.dax-0  (0.001 seconds) - FINISHED 
2023.10.16 22:08:12.125 UTC: [INFO] event.pegasus.refinement dax.id gw.dax-0  (0.069 seconds) - FINISHED 
2023.10.16 22:08:12.143 UTC: [INFO]  Generating codes for the executable workflow 
2023.10.16 22:08:12.143 UTC: [INFO] event.pegasus.code.generation dax.id gw.dax-0  - STARTED 
2023.10.16 22:08:12.143 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:08:12.158 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:08:12.392 UTC: [CONFIG]  Enforce strict checks for worker package in PegasusLite: true 
2023.10.16 22:08:12.392 UTC: [CONFIG]  Allow download of worker package in PegasusLite from Pegasus Website: true 
2023.10.16 22:08:12.394 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:08:12.405 UTC: [CONFIG]  Enforce strict checks for worker package in PegasusLite: false 
2023.10.16 22:08:12.405 UTC: [CONFIG]  Allow download of worker package in PegasusLite from Pegasus Website: false 
2023.10.16 22:08:12.406 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:08:12.804 UTC:    
2023.10.16 22:08:12.810 UTC:   ----------------------------------------------------------------------- 
2023.10.16 22:08:12.815 UTC:   File for submitting this DAG to HTCondor           : gw.dax-0.dag.condor.sub 
2023.10.16 22:08:12.820 UTC:   Log of DAGMan debugging messages                 : gw.dax-0.dag.dagman.out 
2023.10.16 22:08:12.826 UTC:   Log of HTCondor library output                     : gw.dax-0.dag.lib.out 
2023.10.16 22:08:12.831 UTC:   Log of HTCondor library error messages             : gw.dax-0.dag.lib.err 
2023.10.16 22:08:12.837 UTC:   Log of the life of condor_dagman itself          : gw.dax-0.dag.dagman.log 
2023.10.16 22:08:12.843 UTC:    
2023.10.16 22:08:12.848 UTC:   -no_submit given, not submitting DAG to HTCondor.  You can do this with: 
2023.10.16 22:08:12.858 UTC:   ----------------------------------------------------------------------- 
2023.10.16 22:08:12.865 UTC: [INFO] event.pegasus.code.generation dax.id gw.dax-0  (0.722 seconds) - FINISHED 
2023.10.16 22:08:13.881 UTC:   Database version: '5.0.6' (sqlite:////home/poseidon/.pegasus/workflow.db) 
2023.10.16 22:08:15.025 UTC:   Pegasus database was successfully created. 
2023.10.16 22:08:15.030 UTC:   Database version: '5.0.6' (sqlite:////home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.yhoRUb9E5x/work/gw.dax-0.replicas.db) 
2023.10.16 22:08:15.075 UTC:   Output replica catalog set to jdbc:sqlite:/home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.yhoRUb9E5x/work/gw.dax-0.replicas.db 
2023.10.16 22:08:15.291 UTC:   Submitting to condor gw.dax-0.dag.condor.sub 
2023.10.16 22:08:15.865 UTC:   Submitting job(s). 
2023.10.16 22:08:15.865 UTC:    
2023.10.16 22:08:15.870 UTC:   1 job(s) submitted to cluster 296. 
2023.10.16 22:08:15.870 UTC:   Your workflow has been started and is running in the base directory: 
2023.10.16 22:08:15.876 UTC:    
2023.10.16 22:08:15.881 UTC:   /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.yhoRUb9E5x/work 
2023.10.16 22:08:15.886 UTC:    
2023.10.16 22:08:15.892 UTC:   *** To monitor the workflow you can run *** 
2023.10.16 22:08:15.897 UTC:    
2023.10.16 22:08:15.902 UTC:   pegasus-status -l /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.yhoRUb9E5x/work 
2023.10.16 22:08:15.907 UTC:    
2023.10.16 22:08:15.912 UTC:   *** To remove your workflow run *** 
2023.10.16 22:08:15.918 UTC:    
2023.10.16 22:08:15.923 UTC:   pegasus-remove /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.yhoRUb9E5x/work 
2023.10.16 22:08:16.191 UTC:   Time taken to execute is 4.945 seconds 
2023.10.16 22:08:16.191 UTC: [INFO] event.pegasus.planner planner.version 5.0.6  (5.118 seconds) - FINISHED 

Workflow submission completed successfully.

The Pegasus dashboard URL for this workflow is:
  https:///pegasus/u/poseidon/r//w?wf_uuid=

Note that it make take a while for the dashboard entry to appear while the workflow
is parsed by the dashboard. The delay can be on the order of one hour for very large
workflows.

Generating concrete workflow
2023.10.16 22:10:16.158 UTC: [WARNING]  --dax option is deprecated. The abstract workflow is passed via the last positional argument on the commandline. 
2023.10.16 22:10:16.169 UTC: [INFO]  Planner launched in the following directory /home/poseidon/workflows/pycbc/inference/pycbc/gw_output 
2023.10.16 22:10:16.170 UTC: [INFO]  Planner invoked with following arguments --conf ./pegasus-properties.conf --dir ./pycbc-tmp.cmnh1JYmJj --submit --output-sites local --sites local,condorpool_shared --staging-site local=local,condorpool_shared=condorpool_shared --cluster label,horizontal --cleanup inplace --relative-dir work -q --dax gw.dax  
2023.10.16 22:10:16.171 UTC: [CONFIG]  Pegasus Properties set by the user 
2023.10.16 22:10:16.171 UTC: [CONFIG]  pegasus.catalog.replica.cache.asrc=true 
2023.10.16 22:10:16.171 UTC: [CONFIG]  pegasus.catalog.replica.dax.asrc=true 
2023.10.16 22:10:16.172 UTC: [CONFIG]  pegasus.catalog.workflow.amqp.url=amqp://friend:donatedata@msgs.pegasus.isi.edu:5672/prod/workflows 
2023.10.16 22:10:16.172 UTC: [CONFIG]  pegasus.dir.staging.mapper=Flat 
2023.10.16 22:10:16.172 UTC: [CONFIG]  pegasus.dir.storage.mapper=Replica 
2023.10.16 22:10:16.172 UTC: [CONFIG]  pegasus.dir.storage.mapper.replica=File 
2023.10.16 22:10:16.172 UTC: [CONFIG]  pegasus.dir.storage.mapper.replica.file=output.map 
2023.10.16 22:10:16.172 UTC: [CONFIG]  pegasus.dir.submit.mapper=Named 
2023.10.16 22:10:16.172 UTC: [CONFIG]  pegasus.file.cleanup.scope=deferred 
2023.10.16 22:10:16.173 UTC: [CONFIG]  pegasus.home.bindir=/usr/bin 
2023.10.16 22:10:16.173 UTC: [CONFIG]  pegasus.home.schemadir=/usr/share/pegasus/schema 
2023.10.16 22:10:16.173 UTC: [CONFIG]  pegasus.home.sharedstatedir=/usr/share/pegasus 
2023.10.16 22:10:16.173 UTC: [CONFIG]  pegasus.home.sysconfdir=/etc/pegasus 
2023.10.16 22:10:16.173 UTC: [CONFIG]  pegasus.integrity.checking=nosymlink 
2023.10.16 22:10:16.173 UTC: [CONFIG]  pegasus.metrics.app=ligo-pycbc 
2023.10.16 22:10:16.173 UTC: [CONFIG]  pegasus.mode=development 
2023.10.16 22:10:16.173 UTC: [CONFIG]  pegasus.monitord.encoding=json 
2023.10.16 22:10:16.174 UTC: [CONFIG]  pegasus.register=False 
2023.10.16 22:10:16.174 UTC: [CONFIG]  pegasus.selector.replica=Regex 
2023.10.16 22:10:16.174 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.1=osdf:///* 
2023.10.16 22:10:16.174 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.2=file://(?!.*(cvmfs)).* 
2023.10.16 22:10:16.174 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.3=file:///cvmfs/.* 
2023.10.16 22:10:16.174 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.4=root://.* 
2023.10.16 22:10:16.174 UTC: [CONFIG]  pegasus.selector.replica.regex.rank.5=.* 
2023.10.16 22:10:16.174 UTC: [CONFIG]  pegasus.transfer.bypass.input.staging=true 
2023.10.16 22:10:16.175 UTC: [CONFIG]  pegasus.transfer.links=true 
2023.10.16 22:10:16.175 UTC: [CONFIG]  pegasus.transfer.worker.package=true 
2023.10.16 22:10:17.048 UTC: [INFO] event.pegasus.add.data-dependencies dax.id gw.dax-0  - STARTED 
2023.10.16 22:10:17.049 UTC: [INFO] event.pegasus.add.data-dependencies dax.id gw.dax-0  (0.0 seconds) - FINISHED 
2023.10.16 22:10:17.072 UTC: [CONFIG]  Loading site catalog file /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/sites.yml 
2023.10.16 22:10:17.141 UTC: [CONFIG]  Set environment profile for local site PATH=/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/poseidon/go/bin 
2023.10.16 22:10:17.141 UTC: [CONFIG]  Constructed default site catalog entry for condorpool site <site  handle="condorpool" arch="x86_64" os="linux" osrelease="" osversion="" glibc="">
	<profile namespace="pegasus" key="style" >condor</profile>
</site>
 
2023.10.16 22:10:17.398 UTC: [CONFIG]  Transformation Catalog Type used YAML TC 
2023.10.16 22:10:17.402 UTC: [CONFIG]  Transformation Catalog Type used Multiline Textual TC 
2023.10.16 22:10:17.402 UTC: [CONFIG]  Transformation Catalog File used /tmp/tc.15262779426937446490.txt 
2023.10.16 22:10:17.406 UTC: [CONFIG]  Data Configuration used for the workflow condorio 
2023.10.16 22:10:17.407 UTC: [CONFIG]  Metrics file will be written out to /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.cmnh1JYmJj/work/gw.dax-0.metrics 
2023.10.16 22:10:17.407 UTC: [CONFIG]  The base submit directory for the workflow        /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.cmnh1JYmJj 
2023.10.16 22:10:17.408 UTC: [CONFIG]  The relative submit directory for the workflow    work 
2023.10.16 22:10:17.408 UTC: [CONFIG]  The relative execution directory for the workflow work 
2023.10.16 22:10:17.409 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  - STARTED 
2023.10.16 22:10:17.412 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  (0.003 seconds) - FINISHED 
2023.10.16 22:10:17.413 UTC: [INFO] event.pegasus.refinement dax.id gw.dax-0  - STARTED 
2023.10.16 22:10:17.416 UTC: [CONFIG]  Proxy used for Replica Catalog is /tmp/x509up_u1001 
2023.10.16 22:10:17.420 UTC: [INFO] event.pegasus.check.cyclic-dependencies dax.id gw.dax-0  - STARTED 
2023.10.16 22:10:17.420 UTC: [INFO] event.pegasus.check.cyclic-dependencies dax.id gw.dax-0  (0.0 seconds) - FINISHED 
2023.10.16 22:10:17.421 UTC: [CONFIG]  Data Reuse Scope for the workflow: full 
2023.10.16 22:10:17.421 UTC: [INFO] event.pegasus.reduce dax.id gw.dax-0  - STARTED 
2023.10.16 22:10:17.422 UTC: [INFO]  Nodes/Jobs Deleted from the Workflow during reduction  
2023.10.16 22:10:17.422 UTC: [INFO]  Nodes/Jobs Deleted from the Workflow during reduction  - DONE 
2023.10.16 22:10:17.422 UTC: [INFO] event.pegasus.reduce dax.id gw.dax-0  (0.001 seconds) - FINISHED 
2023.10.16 22:10:17.422 UTC: [INFO] event.pegasus.siteselection dax.id gw.dax-0  - STARTED 
2023.10.16 22:10:17.428 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  - STARTED 
2023.10.16 22:10:17.428 UTC: [INFO] event.pegasus.stampede.events dax.id gw.dax-0  (0.0 seconds) - FINISHED 
2023.10.16 22:10:17.428 UTC: [INFO] event.pegasus.siteselection dax.id gw.dax-0  (0.006 seconds) - FINISHED 
2023.10.16 22:10:17.440 UTC: [CONFIG]  No Replica Registration Jobs will be created . 
2023.10.16 22:10:17.443 UTC: [CONFIG]  Transfer Implementation loaded for Stage-In   [Python based Transfer Script] 
2023.10.16 22:10:17.443 UTC: [CONFIG]  Transfer Implementation loaded for symbolic linking Stage-In  [Python based Transfer Script] 
2023.10.16 22:10:17.443 UTC: [CONFIG]  Transfer Implementation loaded for Inter Site [Python based Transfer Script] 
2023.10.16 22:10:17.443 UTC: [CONFIG]  Transfer Implementation loaded for Stage-Out  [Python based Transfer Script] 
2023.10.16 22:10:17.445 UTC: [INFO] event.pegasus.cluster dax.id gw.dax-0  - STARTED 
2023.10.16 22:10:17.448 UTC: [CONFIG]  Partitioner loaded is Label Based Partitioning 
2023.10.16 22:10:17.454 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:10:17.455 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:10:17.456 UTC: [CONFIG]  Clusterer loaded is Topological based Vertical Clustering 
2023.10.16 22:10:17.456 UTC: [INFO]  Starting Graph Traversal 
2023.10.16 22:10:17.457 UTC: [INFO]  Starting Graph Traversal - DONE 
2023.10.16 22:10:17.457 UTC: [INFO]  Determining relations between partitions 
2023.10.16 22:10:17.458 UTC: [INFO]  Determining relations between partitions - DONE 
2023.10.16 22:10:17.458 UTC: [CONFIG]  Partitioner loaded is Level Based Partitioning 
2023.10.16 22:10:17.459 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:10:17.460 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:10:17.460 UTC: [CONFIG]  Clusterer loaded is Horizontal Clustering 
2023.10.16 22:10:17.460 UTC: [INFO] event.pegasus.cluster dax.id gw.dax-0  (0.015 seconds) - FINISHED 
2023.10.16 22:10:17.462 UTC: [INFO]  Grafting transfer nodes in the workflow 
2023.10.16 22:10:17.462 UTC: [INFO] event.pegasus.generate.transfer-nodes dax.id gw.dax-0  - STARTED 
2023.10.16 22:10:17.467 UTC: [CONFIG]  No Replica Registration Jobs will be created . 
2023.10.16 22:10:17.468 UTC: [CONFIG]  Transfer Implementation loaded for Stage-In   [Python based Transfer Script] 
2023.10.16 22:10:17.468 UTC: [CONFIG]  Transfer Implementation loaded for symbolic linking Stage-In  [Python based Transfer Script] 
2023.10.16 22:10:17.468 UTC: [CONFIG]  Transfer Implementation loaded for Inter Site [Python based Transfer Script] 
2023.10.16 22:10:17.468 UTC: [CONFIG]  Transfer Implementation loaded for Stage-Out  [Python based Transfer Script] 
2023.10.16 22:10:17.470 UTC: [CONFIG]  [RegexReplicaSelector] User Provided Ranked regexes are [( rank => 1 priority => 400 expr => osdf:///*), ( rank => 2 priority => 300 expr => file://(?!.*(cvmfs)).*), ( rank => 3 priority => 200 expr => file:///cvmfs/.*), ( rank => 4 priority => 100 expr => root://.*), ( rank => 5 priority => 0 expr => .*)] 
2023.10.16 22:10:17.472 UTC: [CONFIG]  Output Mapper loaded is              [Replica Catalog Mapper] 
2023.10.16 22:10:17.473 UTC: [CONFIG]  Transfer Refiner loaded is           [Balanced Cluster Transfer Refiner( round robin distribution at file level)] 
2023.10.16 22:10:17.473 UTC: [CONFIG]  ReplicaSelector loaded is            [Regex] 
2023.10.16 22:10:17.473 UTC: [CONFIG]  Submit Directory Mapper loaded is    [Relative Submit Directory Mapper] 
2023.10.16 22:10:17.473 UTC: [CONFIG]  Staging Mapper loaded is             [Flat Directory Staging Mapper] 
2023.10.16 22:10:17.477 UTC: [INFO] event.pegasus.generate.transfer-nodes dax.id gw.dax-0  (0.015 seconds) - FINISHED 
2023.10.16 22:10:17.477 UTC: [INFO] event.pegasus.generate.workdir-nodes dax.id gw.dax-0  - STARTED 
2023.10.16 22:10:17.479 UTC: [INFO] event.pegasus.generate.workdir-nodes dax.id gw.dax-0  (0.002 seconds) - FINISHED 
2023.10.16 22:10:17.479 UTC: [INFO] event.pegasus.generate.cleanup-nodes dax.id gw.dax-0  - STARTED 
2023.10.16 22:10:17.481 UTC: [CONFIG]  Setting property dagman.cleanup.maxjobs to  4 to set max jobs for cleanup jobs category 
2023.10.16 22:10:17.482 UTC: [INFO]  For site: local number of files cleaned up - 0 
2023.10.16 22:10:17.482 UTC: [INFO] event.pegasus.generate.cleanup-nodes dax.id gw.dax-0  (0.003 seconds) - FINISHED 
2023.10.16 22:10:17.482 UTC: [INFO] Adding Leaf Cleanup Jobs dax.id gw.dax-0  - STARTED 
2023.10.16 22:10:17.484 UTC: [INFO] Adding Leaf Cleanup Jobs dax.id gw.dax-0  (0.002 seconds) - FINISHED 
2023.10.16 22:10:17.485 UTC: [INFO] event.pegasus.refinement dax.id gw.dax-0  (0.072 seconds) - FINISHED 
2023.10.16 22:10:17.502 UTC: [INFO]  Generating codes for the executable workflow 
2023.10.16 22:10:17.502 UTC: [INFO] event.pegasus.code.generation dax.id gw.dax-0  - STARTED 
2023.10.16 22:10:17.502 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:10:17.518 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:10:17.753 UTC: [CONFIG]  Enforce strict checks for worker package in PegasusLite: true 
2023.10.16 22:10:17.753 UTC: [CONFIG]  Allow download of worker package in PegasusLite from Pegasus Website: true 
2023.10.16 22:10:17.755 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:10:17.766 UTC: [CONFIG]  Enforce strict checks for worker package in PegasusLite: false 
2023.10.16 22:10:17.766 UTC: [CONFIG]  Allow download of worker package in PegasusLite from Pegasus Website: false 
2023.10.16 22:10:17.767 UTC: [CONFIG]  Kickstart Stating Disabled Completely - false 
2023.10.16 22:10:18.168 UTC:    
2023.10.16 22:10:18.179 UTC:   ----------------------------------------------------------------------- 
2023.10.16 22:10:18.184 UTC:   File for submitting this DAG to HTCondor           : gw.dax-0.dag.condor.sub 
2023.10.16 22:10:18.190 UTC:   Log of DAGMan debugging messages                 : gw.dax-0.dag.dagman.out 
2023.10.16 22:10:18.195 UTC:   Log of HTCondor library output                     : gw.dax-0.dag.lib.out 
2023.10.16 22:10:18.200 UTC:   Log of HTCondor library error messages             : gw.dax-0.dag.lib.err 
2023.10.16 22:10:18.206 UTC:   Log of the life of condor_dagman itself          : gw.dax-0.dag.dagman.log 
2023.10.16 22:10:18.212 UTC:    
2023.10.16 22:10:18.219 UTC:   -no_submit given, not submitting DAG to HTCondor.  You can do this with: 
2023.10.16 22:10:18.229 UTC:   ----------------------------------------------------------------------- 
2023.10.16 22:10:18.236 UTC: [INFO] event.pegasus.code.generation dax.id gw.dax-0  (0.734 seconds) - FINISHED 
2023.10.16 22:10:19.230 UTC:   Database version: '5.0.6' (sqlite:////home/poseidon/.pegasus/workflow.db) 
2023.10.16 22:10:20.369 UTC:   Pegasus database was successfully created. 
2023.10.16 22:10:20.374 UTC:   Database version: '5.0.6' (sqlite:////home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.cmnh1JYmJj/work/gw.dax-0.replicas.db) 
2023.10.16 22:10:20.421 UTC:   Output replica catalog set to jdbc:sqlite:/home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.cmnh1JYmJj/work/gw.dax-0.replicas.db 
2023.10.16 22:10:20.633 UTC:   Submitting to condor gw.dax-0.dag.condor.sub 
2023.10.16 22:10:21.203 UTC:   Submitting job(s). 
2023.10.16 22:10:21.203 UTC:    
2023.10.16 22:10:21.208 UTC:   1 job(s) submitted to cluster 298. 
2023.10.16 22:10:21.209 UTC:   Your workflow has been started and is running in the base directory: 
2023.10.16 22:10:21.214 UTC:    
2023.10.16 22:10:21.220 UTC:   /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.cmnh1JYmJj/work 
2023.10.16 22:10:21.225 UTC:    
2023.10.16 22:10:21.230 UTC:   *** To monitor the workflow you can run *** 
2023.10.16 22:10:21.235 UTC:    
2023.10.16 22:10:21.240 UTC:   pegasus-status -l /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.cmnh1JYmJj/work 
2023.10.16 22:10:21.245 UTC:    
2023.10.16 22:10:21.250 UTC:   *** To remove your workflow run *** 
2023.10.16 22:10:21.255 UTC:    
2023.10.16 22:10:21.261 UTC:   pegasus-remove /home/poseidon/workflows/pycbc/inference/pycbc/gw_output/pycbc-tmp.cmnh1JYmJj/work 
2023.10.16 22:10:21.502 UTC:   Time taken to execute is 5.207 seconds 
2023.10.16 22:10:21.502 UTC: [INFO] event.pegasus.planner planner.version 5.0.6  (5.35 seconds) - FINISHED 

Workflow submission completed successfully.

The Pegasus dashboard URL for this workflow is:
  https:///pegasus/u/poseidon/r//w?wf_uuid=

Note that it make take a while for the dashboard entry to appear while the workflow
is parsed by the dashboard. The delay can be on the order of one hour for very large
workflows.

